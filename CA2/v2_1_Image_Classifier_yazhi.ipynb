{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VnqVd3nZc7JK"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,CSVLogger,LearningRateScheduler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import add\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "vZSnbxjk04m8",
    "outputId": "092cc967-3676-4bb4-f90d-a55fd36b3571"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['food', 'landmark', 'people']\n",
      "['food', 'landmark', 'people']\n"
     ]
    }
   ],
   "source": [
    "train_dir = r\"D:\\NUS_TERM2_CA2\\Train\"\n",
    "print(os.listdir(train_dir))\n",
    "\n",
    "validation_dir = r\"D:\\NUS_TERM2_CA2\\Validation\"\n",
    "print(os.listdir(validation_dir))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lo0G8cHAsQIq"
   },
   "source": [
    "# Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wrFb8TjYwg_G"
   },
   "outputs": [],
   "source": [
    "def resLyr(inputs,\n",
    "           numFilters=16,\n",
    "           kernelSz=3,\n",
    "           strides=1,\n",
    "           activation='relu',\n",
    "           batchNorm=True,\n",
    "           convFirst=True,\n",
    "           lyrName=None):\n",
    "  \n",
    "  convLyr = Conv2D(numFilters,\n",
    "                  kernel_size=kernelSz,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4),\n",
    "                  name=lyrName+'_conv' if lyrName else None)\n",
    "  x = inputs\n",
    "  if convFirst:\n",
    "    x = convLyr(x)\n",
    "    if batchNorm:\n",
    "      x = BatchNormalization(name=lyrName+'_bn' if lyrName else None)(x)\n",
    "    if activation is not None:\n",
    "      x = Activation(activation, name=lyrName+'_'+activation if lyrName else None)(x)\n",
    "  else:\n",
    "    if batchNorm:\n",
    "      x = BatchNormalization(name=lyrName+'_bn' if lyrName else None)(x)\n",
    "    if activation is not None:\n",
    "      x = Activation(activation, name=lyrName+'_'+activation if lyrName else None)(x) \n",
    "    x = convLyr(x)\n",
    "\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a2qOsKFasZya"
   },
   "outputs": [],
   "source": [
    "def resBlkV1(inputs,\n",
    "             numFilters=16,\n",
    "             numBlocks=3,\n",
    "             downsampleOnFirst=True,\n",
    "             names=None):\n",
    "  x = inputs\n",
    "  for run in range(0, numBlocks):\n",
    "    strides = 1\n",
    "    blkStr = str(run + 1)\n",
    "    if downsampleOnFirst and run == 0:\n",
    "      strides = 2\n",
    "    y = resLyr(inputs=x,\n",
    "              numFilters=numFilters,\n",
    "              strides=strides,\n",
    "              lyrName=names+'_blk'+blkStr+'_Res1' if names else None)\n",
    "    y = resLyr(inputs=y,\n",
    "              numFilters=numFilters,\n",
    "              activation=None,\n",
    "              lyrName=names+'_blk'+blkStr+'_Res2' if names else None)\n",
    "    if downsampleOnFirst and run == 0:\n",
    "      x = resLyr(inputs=x,\n",
    "                numFilters=numFilters,\n",
    "                kernelSz=1,\n",
    "                strides=strides,\n",
    "                activation=None,\n",
    "                batchNorm=False,\n",
    "                lyrName=names+'_blk'+blkStr+'_lin' if names else None)\n",
    "    x = add([x,y],\n",
    "            name=names+'_Blk'+blkStr+'_add' if names else None)\n",
    "    x = Activation('relu', name=names+'_Blk'+blkStr+'_relu' if names else None)(x)\n",
    "        \n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2yDKI-JOsZ8j"
   },
   "outputs": [],
   "source": [
    "def createResNetV1(inputShape=(32,32,3),\n",
    "                   numClasses=3):\n",
    "  inputs = Input(shape=inputShape)\n",
    "  v = resLyr(inputs, lyrName='inpt')\n",
    "  v = resBlkV1(inputs=v,\n",
    "              numFilters=16,\n",
    "              numBlocks=3,\n",
    "              downsampleOnFirst=False,\n",
    "              names='Stg1')\n",
    "  v = resBlkV1(inputs=v,\n",
    "              numFilters=32,\n",
    "              numBlocks=3,\n",
    "              downsampleOnFirst=True,\n",
    "              names='Stg2')\n",
    "  v = resBlkV1(inputs=v,\n",
    "              numFilters=64,\n",
    "              numBlocks=3,\n",
    "              downsampleOnFirst=True,\n",
    "              names='Stg3')\n",
    "  \n",
    "  '''v = resLyr(inputs=v,\n",
    "            numFilters=64,\n",
    "            kernelSz=3,\n",
    "            strides=1,\n",
    "            activation='relu',\n",
    "            batchNorm=True,\n",
    "            convFirst=True,\n",
    "            lyrName='NEW'\n",
    "            )'''\n",
    "  \n",
    "  v = AveragePooling2D(pool_size=8, name='AvgPool')(v)\n",
    "  \n",
    "  v = Flatten()(v)\n",
    "  outputs = Dense(numClasses,\n",
    "                 activation='softmax',\n",
    "                 kernel_initializer='he_normal')(v)\n",
    "  \n",
    "  model = Model(inputs=inputs, outputs=outputs)\n",
    "  model.compile(loss='categorical_crossentropy',\n",
    "               optimizer='rmsprop',\n",
    "               metrics=['accuracy'])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Nz4cyET2o50R",
    "outputId": "b0f004e3-4ba9-45e2-8b48-12e9cecdc0b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inpt_conv (Conv2D)              (None, 32, 32, 16)   448         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "inpt_bn (BatchNormalization)    (None, 32, 32, 16)   64          inpt_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "inpt_relu (Activation)          (None, 32, 32, 16)   0           inpt_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_blk1_Res1_conv (Conv2D)    (None, 32, 32, 16)   2320        inpt_relu[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_blk1_Res1_bn (BatchNormali (None, 32, 32, 16)   64          Stg1_blk1_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_blk1_Res1_relu (Activation (None, 32, 32, 16)   0           Stg1_blk1_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_blk1_Res2_conv (Conv2D)    (None, 32, 32, 16)   2320        Stg1_blk1_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_blk1_Res2_bn (BatchNormali (None, 32, 32, 16)   64          Stg1_blk1_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_add (Add)             (None, 32, 32, 16)   0           inpt_relu[0][0]                  \n",
      "                                                                 Stg1_blk1_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_relu (Activation)     (None, 32, 32, 16)   0           Stg1_Blk1_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_blk2_Res1_conv (Conv2D)    (None, 32, 32, 16)   2320        Stg1_Blk1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_blk2_Res1_bn (BatchNormali (None, 32, 32, 16)   64          Stg1_blk2_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_blk2_Res1_relu (Activation (None, 32, 32, 16)   0           Stg1_blk2_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_blk2_Res2_conv (Conv2D)    (None, 32, 32, 16)   2320        Stg1_blk2_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_blk2_Res2_bn (BatchNormali (None, 32, 32, 16)   64          Stg1_blk2_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_add (Add)             (None, 32, 32, 16)   0           Stg1_Blk1_relu[0][0]             \n",
      "                                                                 Stg1_blk2_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_relu (Activation)     (None, 32, 32, 16)   0           Stg1_Blk2_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_blk3_Res1_conv (Conv2D)    (None, 32, 32, 16)   2320        Stg1_Blk2_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_blk3_Res1_bn (BatchNormali (None, 32, 32, 16)   64          Stg1_blk3_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_blk3_Res1_relu (Activation (None, 32, 32, 16)   0           Stg1_blk3_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_blk3_Res2_conv (Conv2D)    (None, 32, 32, 16)   2320        Stg1_blk3_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_blk3_Res2_bn (BatchNormali (None, 32, 32, 16)   64          Stg1_blk3_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_add (Add)             (None, 32, 32, 16)   0           Stg1_Blk2_relu[0][0]             \n",
      "                                                                 Stg1_blk3_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_relu (Activation)     (None, 32, 32, 16)   0           Stg1_Blk3_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_blk1_Res1_conv (Conv2D)    (None, 16, 16, 32)   4640        Stg1_Blk3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_blk1_Res1_bn (BatchNormali (None, 16, 16, 32)   128         Stg2_blk1_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_blk1_Res1_relu (Activation (None, 16, 16, 32)   0           Stg2_blk1_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_blk1_Res2_conv (Conv2D)    (None, 16, 16, 32)   9248        Stg2_blk1_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_blk1_lin_conv (Conv2D)     (None, 16, 16, 32)   544         Stg1_Blk3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_blk1_Res2_bn (BatchNormali (None, 16, 16, 32)   128         Stg2_blk1_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_add (Add)             (None, 16, 16, 32)   0           Stg2_blk1_lin_conv[0][0]         \n",
      "                                                                 Stg2_blk1_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_relu (Activation)     (None, 16, 16, 32)   0           Stg2_Blk1_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_blk2_Res1_conv (Conv2D)    (None, 16, 16, 32)   9248        Stg2_Blk1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_blk2_Res1_bn (BatchNormali (None, 16, 16, 32)   128         Stg2_blk2_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_blk2_Res1_relu (Activation (None, 16, 16, 32)   0           Stg2_blk2_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_blk2_Res2_conv (Conv2D)    (None, 16, 16, 32)   9248        Stg2_blk2_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_blk2_Res2_bn (BatchNormali (None, 16, 16, 32)   128         Stg2_blk2_Res2_conv[0][0]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_add (Add)             (None, 16, 16, 32)   0           Stg2_Blk1_relu[0][0]             \n",
      "                                                                 Stg2_blk2_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_relu (Activation)     (None, 16, 16, 32)   0           Stg2_Blk2_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_blk3_Res1_conv (Conv2D)    (None, 16, 16, 32)   9248        Stg2_Blk2_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_blk3_Res1_bn (BatchNormali (None, 16, 16, 32)   128         Stg2_blk3_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_blk3_Res1_relu (Activation (None, 16, 16, 32)   0           Stg2_blk3_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_blk3_Res2_conv (Conv2D)    (None, 16, 16, 32)   9248        Stg2_blk3_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_blk3_Res2_bn (BatchNormali (None, 16, 16, 32)   128         Stg2_blk3_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_add (Add)             (None, 16, 16, 32)   0           Stg2_Blk2_relu[0][0]             \n",
      "                                                                 Stg2_blk3_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_relu (Activation)     (None, 16, 16, 32)   0           Stg2_Blk3_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_blk1_Res1_conv (Conv2D)    (None, 8, 8, 64)     18496       Stg2_Blk3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_blk1_Res1_bn (BatchNormali (None, 8, 8, 64)     256         Stg3_blk1_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_blk1_Res1_relu (Activation (None, 8, 8, 64)     0           Stg3_blk1_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_blk1_Res2_conv (Conv2D)    (None, 8, 8, 64)     36928       Stg3_blk1_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_blk1_lin_conv (Conv2D)     (None, 8, 8, 64)     2112        Stg2_Blk3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_blk1_Res2_bn (BatchNormali (None, 8, 8, 64)     256         Stg3_blk1_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_add (Add)             (None, 8, 8, 64)     0           Stg3_blk1_lin_conv[0][0]         \n",
      "                                                                 Stg3_blk1_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_relu (Activation)     (None, 8, 8, 64)     0           Stg3_Blk1_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_blk2_Res1_conv (Conv2D)    (None, 8, 8, 64)     36928       Stg3_Blk1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_blk2_Res1_bn (BatchNormali (None, 8, 8, 64)     256         Stg3_blk2_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_blk2_Res1_relu (Activation (None, 8, 8, 64)     0           Stg3_blk2_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_blk2_Res2_conv (Conv2D)    (None, 8, 8, 64)     36928       Stg3_blk2_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_blk2_Res2_bn (BatchNormali (None, 8, 8, 64)     256         Stg3_blk2_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_add (Add)             (None, 8, 8, 64)     0           Stg3_Blk1_relu[0][0]             \n",
      "                                                                 Stg3_blk2_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_relu (Activation)     (None, 8, 8, 64)     0           Stg3_Blk2_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_blk3_Res1_conv (Conv2D)    (None, 8, 8, 64)     36928       Stg3_Blk2_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_blk3_Res1_bn (BatchNormali (None, 8, 8, 64)     256         Stg3_blk3_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_blk3_Res1_relu (Activation (None, 8, 8, 64)     0           Stg3_blk3_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_blk3_Res2_conv (Conv2D)    (None, 8, 8, 64)     36928       Stg3_blk3_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_blk3_Res2_bn (BatchNormali (None, 8, 8, 64)     256         Stg3_blk3_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_add (Add)             (None, 8, 8, 64)     0           Stg3_Blk2_relu[0][0]             \n",
      "                                                                 Stg3_blk3_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_relu (Activation)     (None, 8, 8, 64)     0           Stg3_Blk3_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "AvgPool (AveragePooling2D)      (None, 1, 1, 64)     0           Stg3_Blk3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 64)           0           AvgPool[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3)            195         flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 273,987\n",
      "Trainable params: 272,611\n",
      "Non-trainable params: 1,376\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = createResNetV1()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E73eJXM5t5oS"
   },
   "source": [
    "# Data Flow into Model For Accuracy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrSchedule(epoch):\n",
    "    lr  = 1e-3\n",
    "    \n",
    "    if epoch > 160:\n",
    "        lr  *= 0.5e-3\n",
    "        \n",
    "    elif epoch > 140:\n",
    "        lr  *= 1e-3\n",
    "        \n",
    "    elif epoch > 120:\n",
    "        lr  *= 1e-2\n",
    "        \n",
    "    elif epoch > 80:\n",
    "        lr  *= 1e-1\n",
    "        \n",
    "    print('Learning rate: ', lr)\n",
    "    \n",
    "    return lr\n",
    "\n",
    "LRScheduler = LearningRateScheduler(lrSchedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tJJYqVWppHxi"
   },
   "outputs": [],
   "source": [
    "modelname = 'createResNetV1'\n",
    "filepath = modelname + '.hdf5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath,\n",
    "                            monitor='val_acc',\n",
    "                            verbose=0,\n",
    "                            save_best_only=True,\n",
    "                            mode='max')\n",
    "\n",
    "csv_logger = CSVLogger(modelname + '.csv')\n",
    "callbacks_list = [checkpoint, csv_logger, LRScheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DRP7d9Ti_7Zk"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "      width_shift_range=0.1,\n",
    "  height_shift_range=0.1,\n",
    "                             rotation_range=90,\n",
    "                             horizontal_flip=True,\n",
    "                             vertical_flip=False,\n",
    "    rescale=1./255)\n",
    "\n",
    "batch_size = 128\n",
    "img_width, img_height = 32, 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mLKvbr48_7dM",
    "outputId": "9336b1cd-2db7-4c11-b71f-3ee0d1aea824"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2423 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_directory(\n",
    "  directory=train_dir ,\n",
    "  target_size=(img_width, img_height),\n",
    "  color_mode='rgb',\n",
    "  batch_size=batch_size,\n",
    "  class_mode='categorical',\n",
    "  shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen2 = ImageDataGenerator(\n",
    "    rescale=1./255)\n",
    "\n",
    "batch_size = 128\n",
    "img_width, img_height = 32, 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3a4ApY-_vF9s",
    "outputId": "ca48e356-95eb-4205-b7a2-61907ada2375"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 724 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = datagen2.flow_from_directory(\n",
    "  directory=validation_dir ,\n",
    "  target_size=(img_width, img_height),\n",
    "  color_mode='rgb',\n",
    "  batch_size=batch_size,\n",
    "  class_mode='categorical',\n",
    "  shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "colab_type": "code",
    "id": "uHtEZKOz_7nO",
    "outputId": "3a9826f4-c3ad-4770-97bd-e6a0d0aea8bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Epoch 1/40\n",
      "18/18 [==============================] - ETA: 4:55 - loss: 0.7893 - acc: 0.765 - ETA: 2:19 - loss: 1.5575 - acc: 0.382 - ETA: 1:38 - loss: 1.3787 - acc: 0.481 - ETA: 51s - loss: 1.3785 - acc: 0.412 - ETA: 39s - loss: 1.2797 - acc: 0.49 - ETA: 24s - loss: 1.4714 - acc: 0.38 - ETA: 17s - loss: 1.4267 - acc: 0.40 - ETA: 18s - loss: 1.3902 - acc: 0.40 - ETA: 11s - loss: 1.3357 - acc: 0.41 - ETA: 9s - loss: 1.4195 - acc: 0.3875 - ETA: 6s - loss: 1.4262 - acc: 0.361 - ETA: 2s - loss: 1.3728 - acc: 0.385 - 56s 3s/step - loss: 1.3163 - acc: 0.4200 - val_loss: 1.2382 - val_acc: 0.4641\n",
      "Learning rate:  0.001\n",
      "Epoch 2/40\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2893 - acc: 1.000 - ETA: 1:17 - loss: 0.2651 - acc: 1.000 - ETA: 48s - loss: 1.3195 - acc: 0.666 - ETA: 53s - loss: 1.2624 - acc: 0.56 - ETA: 30s - loss: 1.2553 - acc: 0.54 - ETA: 25s - loss: 1.3486 - acc: 0.50 - ETA: 23s - loss: 1.3433 - acc: 0.50 - ETA: 19s - loss: 1.2629 - acc: 0.55 - ETA: 18s - loss: 1.1758 - acc: 0.60 - ETA: 13s - loss: 1.1903 - acc: 0.58 - ETA: 11s - loss: 1.1911 - acc: 0.54 - ETA: 5s - loss: 1.2713 - acc: 0.5193 - ETA: 1s - loss: 1.3006 - acc: 0.459 - 57s 3s/step - loss: 1.2835 - acc: 0.4683 - val_loss: 1.2136 - val_acc: 0.4641\n",
      "Learning rate:  0.001\n",
      "Epoch 3/40\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.3425 - acc: 0.386 - ETA: 1:29 - loss: 1.4271 - acc: 0.205 - ETA: 46s - loss: 1.1374 - acc: 0.502 - ETA: 36s - loss: 1.3320 - acc: 0.42 - ETA: 28s - loss: 1.2952 - acc: 0.41 - ETA: 18s - loss: 1.1890 - acc: 0.47 - ETA: 15s - loss: 1.2468 - acc: 0.42 - ETA: 12s - loss: 1.2782 - acc: 0.40 - ETA: 10s - loss: 1.2507 - acc: 0.41 - ETA: 6s - loss: 1.2450 - acc: 0.4259 - ETA: 2s - loss: 1.2737 - acc: 0.402 - 56s 3s/step - loss: 1.2533 - acc: 0.4331 - val_loss: 1.3717 - val_acc: 0.4500\n",
      "Learning rate:  0.001\n",
      "Epoch 4/40\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.3802 - acc: 0.0000e+0 - ETA: 0s - loss: 1.2165 - acc: 0.3281    - ETA: 53s - loss: 1.2792 - acc: 0.24 - ETA: 49s - loss: 1.0979 - acc: 0.39 - ETA: 29s - loss: 1.1525 - acc: 0.39 - ETA: 19s - loss: 1.1256 - acc: 0.41 - ETA: 12s - loss: 1.1150 - acc: 0.43 - ETA: 10s - loss: 1.1405 - acc: 0.40 - ETA: 5s - loss: 1.1750 - acc: 0.3578 - ETA: 5s - loss: 1.1649 - acc: 0.340 - ETA: 3s - loss: 1.1708 - acc: 0.320 - ETA: 1s - loss: 1.1350 - acc: 0.360 - 56s 3s/step - loss: 1.1895 - acc: 0.3407 - val_loss: 1.1616 - val_acc: 0.4328\n",
      "Learning rate:  0.001\n",
      "Epoch 5/40\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.8885 - acc: 0.851 - ETA: 0s - loss: 0.9753 - acc: 0.700 - ETA: 40s - loss: 0.7484 - acc: 0.81 - ETA: 31s - loss: 0.7893 - acc: 0.78 - ETA: 19s - loss: 0.9046 - acc: 0.71 - ETA: 14s - loss: 0.8586 - acc: 0.77 - ETA: 13s - loss: 0.8647 - acc: 0.75 - ETA: 9s - loss: 0.8309 - acc: 0.7903 - ETA: 5s - loss: 0.9101 - acc: 0.746 - ETA: 1s - loss: 0.9020 - acc: 0.721 - 55s 3s/step - loss: 0.9908 - acc: 0.6989 - val_loss: 1.5269 - val_acc: 0.4641\n",
      "Learning rate:  0.001\n",
      "Epoch 6/40\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.8538 - acc: 0.859 - ETA: 0s - loss: 0.8580 - acc: 0.802 - ETA: 0s - loss: 0.9395 - acc: 0.682 - ETA: 37s - loss: 0.8285 - acc: 0.73 - ETA: 29s - loss: 0.7458 - acc: 0.77 - ETA: 23s - loss: 0.8589 - acc: 0.67 - ETA: 15s - loss: 0.8447 - acc: 0.73 - ETA: 10s - loss: 0.8576 - acc: 0.72 - ETA: 6s - loss: 0.8266 - acc: 0.7347 - ETA: 5s - loss: 0.7888 - acc: 0.752 - ETA: 3s - loss: 0.7535 - acc: 0.768 - ETA: 1s - loss: 0.7592 - acc: 0.779 - 53s 3s/step - loss: 0.7276 - acc: 0.7913 - val_loss: 1.5773 - val_acc: 0.4641\n",
      "Learning rate:  0.001\n",
      "Epoch 7/40\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.0616 - acc: 0.382 - ETA: 0s - loss: 1.1936 - acc: 0.460 - ETA: 0s - loss: 1.1070 - acc: 0.468 - ETA: 28s - loss: 1.0245 - acc: 0.48 - ETA: 18s - loss: 0.8968 - acc: 0.59 - ETA: 11s - loss: 0.9233 - acc: 0.57 - ETA: 9s - loss: 0.9139 - acc: 0.5807 - ETA: 7s - loss: 0.9826 - acc: 0.540 - ETA: 5s - loss: 0.9555 - acc: 0.566 - ETA: 5s - loss: 0.9518 - acc: 0.570 - ETA: 1s - loss: 0.8685 - acc: 0.620 - 53s 3s/step - loss: 0.8966 - acc: 0.6074 - val_loss: 1.5798 - val_acc: 0.4641\n",
      "Learning rate:  0.001\n",
      "Epoch 8/40\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.6785 - acc: 0.851 - ETA: 0s - loss: 0.6717 - acc: 0.825 - ETA: 0s - loss: 0.6890 - acc: 0.726 - ETA: 0s - loss: 0.9657 - acc: 0.625 - ETA: 9s - loss: 0.9439 - acc: 0.642 - ETA: 7s - loss: 0.8757 - acc: 0.682 - ETA: 7s - loss: 0.8732 - acc: 0.670 - ETA: 11s - loss: 0.8865 - acc: 0.62 - ETA: 7s - loss: 0.8612 - acc: 0.6581 - ETA: 3s - loss: 0.8735 - acc: 0.638 - ETA: 2s - loss: 0.8504 - acc: 0.661 - 51s 3s/step - loss: 0.8317 - acc: 0.6680 - val_loss: 1.4646 - val_acc: 0.2391\n",
      "Learning rate:  0.001\n",
      "Epoch 9/40\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2318 - acc: 1.000 - ETA: 0s - loss: 0.3670 - acc: 1.000 - ETA: 0s - loss: 0.4256 - acc: 0.929 - ETA: 0s - loss: 0.4906 - acc: 0.869 - ETA: 10s - loss: 0.6659 - acc: 0.76 - ETA: 14s - loss: 0.7204 - acc: 0.69 - ETA: 9s - loss: 0.6787 - acc: 0.7448 - ETA: 5s - loss: 0.7036 - acc: 0.728 - ETA: 2s - loss: 0.6804 - acc: 0.751 - 53s 3s/step - loss: 0.7174 - acc: 0.7049 - val_loss: 1.1585 - val_acc: 0.6016\n",
      "Learning rate:  0.001\n",
      "Epoch 10/40\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.6265 - acc: 0.976 - ETA: 0s - loss: 0.6014 - acc: 0.890 - ETA: 0s - loss: 0.9698 - acc: 0.668 - ETA: 0s - loss: 0.7955 - acc: 0.764 - ETA: 0s - loss: 0.7060 - acc: 0.812 - ETA: 11s - loss: 0.6545 - acc: 0.83 - ETA: 7s - loss: 0.6430 - acc: 0.8546 - ETA: 6s - loss: 0.6161 - acc: 0.865 - ETA: 3s - loss: 0.6031 - acc: 0.883 - ETA: 2s - loss: 0.5925 - acc: 0.890 - 48s 3s/step - loss: 0.5592 - acc: 0.9029 - val_loss: 1.4521 - val_acc: 0.2594\n",
      "Learning rate:  0.001\n",
      "Epoch 11/40\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.7719 - acc: 0.757 - ETA: 0s - loss: 0.9860 - acc: 0.815 - ETA: 0s - loss: 0.7380 - acc: 0.882 - ETA: 0s - loss: 0.7921 - acc: 0.773 - ETA: 0s - loss: 1.0682 - acc: 0.651 - ETA: 6s - loss: 0.9679 - acc: 0.711 - ETA: 9s - loss: 1.0492 - acc: 0.654 - ETA: 6s - loss: 1.0501 - acc: 0.644 - ETA: 3s - loss: 0.9713 - acc: 0.682 - ETA: 2s - loss: 0.9237 - acc: 0.702 - ETA: 1s - loss: 0.8838 - acc: 0.719 - 50s 3s/step - loss: 0.8876 - acc: 0.6957 - val_loss: 1.3494 - val_acc: 0.2438\n",
      "Learning rate:  0.001\n",
      "Epoch 12/40\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3786 - acc: 1.000 - ETA: 0s - loss: 0.3507 - acc: 1.000 - ETA: 0s - loss: 0.4148 - acc: 0.911 - ETA: 0s - loss: 0.4859 - acc: 0.863 - ETA: 0s - loss: 0.5125 - acc: 0.872 - ETA: 0s - loss: 0.4564 - acc: 0.895 - ETA: 8s - loss: 0.4326 - acc: 0.904 - ETA: 7s - loss: 0.4338 - acc: 0.911 - ETA: 5s - loss: 0.4687 - acc: 0.879 - ETA: 3s - loss: 0.5260 - acc: 0.821 - ETA: 1s - loss: 0.5313 - acc: 0.808 - 49s 3s/step - loss: 0.5116 - acc: 0.8189 - val_loss: 1.4194 - val_acc: 0.3656\n",
      "Learning rate:  0.001\n",
      "Epoch 13/40\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.8307 - acc: 0.781 - ETA: 0s - loss: 0.9664 - acc: 0.596 - ETA: 0s - loss: 0.8192 - acc: 0.606 - ETA: 0s - loss: 0.7054 - acc: 0.718 - ETA: 0s - loss: 0.7033 - acc: 0.713 - ETA: 0s - loss: 0.7992 - acc: 0.674 - ETA: 4s - loss: 0.7518 - acc: 0.701 - ETA: 7s - loss: 0.7102 - acc: 0.724 - ETA: 7s - loss: 0.6794 - acc: 0.743 - ETA: 3s - loss: 0.6182 - acc: 0.775 - 54s 3s/step - loss: 0.5684 - acc: 0.8008 - val_loss: 1.3138 - val_acc: 0.2188\n",
      "Learning rate:  0.001\n",
      "Epoch 14/40\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1950 - acc: 1.000 - ETA: 0s - loss: 0.4596 - acc: 0.974 - ETA: 0s - loss: 0.4902 - acc: 0.971 - ETA: 0s - loss: 0.4587 - acc: 0.978 - ETA: 0s - loss: 0.5398 - acc: 0.872 - ETA: 0s - loss: 0.6110 - acc: 0.804 - ETA: 6s - loss: 0.6351 - acc: 0.774 - ETA: 8s - loss: 0.6617 - acc: 0.779 - ETA: 3s - loss: 0.6026 - acc: 0.806 - 58s 3s/step - loss: 0.6896 - acc: 0.7353 - val_loss: 1.9437 - val_acc: 0.3547\n",
      "Learning rate:  0.001\n",
      "Epoch 15/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - ETA: 0s - loss: 0.1745 - acc: 1.000 - ETA: 0s - loss: 0.4857 - acc: 0.927 - ETA: 0s - loss: 0.3928 - acc: 0.956 - ETA: 0s - loss: 0.3511 - acc: 0.968 - ETA: 0s - loss: 0.3922 - acc: 0.906 - ETA: 0s - loss: 0.4481 - acc: 0.882 - ETA: 4s - loss: 0.4596 - acc: 0.886 - ETA: 3s - loss: 0.4177 - acc: 0.902 - ETA: 5s - loss: 0.4008 - acc: 0.909 - ETA: 3s - loss: 0.3919 - acc: 0.915 - 57s 3s/step - loss: 0.3669 - acc: 0.9245 - val_loss: 1.4141 - val_acc: 0.2188\n",
      "Learning rate:  0.001\n",
      "Epoch 16/40\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1599 - acc: 1.000 - ETA: 0s - loss: 0.2941 - acc: 1.000 - ETA: 0s - loss: 0.4996 - acc: 0.856 - ETA: 0s - loss: 0.4709 - acc: 0.897 - ETA: 0s - loss: 0.5062 - acc: 0.870 - ETA: 0s - loss: 0.4819 - acc: 0.884 - ETA: 5s - loss: 0.4628 - acc: 0.893 - ETA: 4s - loss: 0.6056 - acc: 0.824 - ETA: 2s - loss: 0.5951 - acc: 0.833 - ETA: 2s - loss: 0.5681 - acc: 0.844 - ETA: 1s - loss: 0.5444 - acc: 0.853 - 58s 3s/step - loss: 0.5329 - acc: 0.8614 - val_loss: 1.3161 - val_acc: 0.2156\n",
      "Learning rate:  0.001\n",
      "Epoch 17/40\n",
      "17/18 [===========================>..] - ETA: 16s - loss: 0.2350 - acc: 1.00 - ETA: 15s - loss: 0.2083 - acc: 1.00 - ETA: 15s - loss: 0.1995 - acc: 1.00 - ETA: 14s - loss: 0.1890 - acc: 1.00 - ETA: 13s - loss: 0.2228 - acc: 1.00 - ETA: 11s - loss: 0.2391 - acc: 1.00 - ETA: 10s - loss: 0.3163 - acc: 0.94 - ETA: 9s - loss: 0.3376 - acc: 0.9330 - ETA: 8s - loss: 0.3731 - acc: 0.919 - ETA: 7s - loss: 0.3521 - acc: 0.927 - ETA: 6s - loss: 0.3424 - acc: 0.934 - ETA: 7s - loss: 0.3636 - acc: 0.935 - ETA: 6s - loss: 0.4787 - acc: 0.916 - ETA: 4s - loss: 0.5087 - acc: 0.878 - ETA: 3s - loss: 0.5008 - acc: 0.884 - ETA: 2s - loss: 0.5029 - acc: 0.891 - ETA: 1s - loss: 0.4828 - acc: 0.8976"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-2e0710218d56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSTEP_SIZE_TRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSTEP_SIZE_VALID\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                     callbacks=callbacks_list)\n\u001b[0m",
      "\u001b[1;32mc:\\users\\guofe\\workspace\\nus_is_pr\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1431\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1432\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1433\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m   1434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32mc:\\users\\guofe\\workspace\\nus_is_pr\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    320\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m           \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m           steps_name='validation_steps')\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_results\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guofe\\workspace\\nus_is_pr\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mtarget_steps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m       \u001b[0mbatch_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_next_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_dataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guofe\\workspace\\nus_is_pr\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36m_get_next_batch\u001b[1;34m(generator, mode)\u001b[0m\n\u001b[0;32m    360\u001b[0m   \u001b[1;34m\"\"\"Retrieves the next batch of input data.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m     \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guofe\\workspace\\nus_is_pr\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    777\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 648\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n",
    "\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    epochs=40,\n",
    "                    workers=8, \n",
    "                    shuffle=True,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = createResNetV1()\n",
    "\n",
    "model2.load_weights(filepath)\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimize='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = model2.predict(validation_x)\n",
    "\n",
    "predout = np.argmax(predicts, axis=1)\n",
    "testout = np.argmax(validation_y, axis=1)\n",
    "\n",
    "labelname = ['food', 'landmark', 'people']\n",
    "\n",
    "testScore = metrics.accruacy_score(testout, predout)\n",
    "confusion = metrics.confusion_matrix(testout, predout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "LMI6xLaieB-j",
    "outputId": "67a00101-b09d-4f35-de30-dbeab8ce1a9a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRUQKkJK7iEgB+v9fgJHiBpW9bgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "records     = pd.read_csv(modelname +'.csv')\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "plt.plot(records['val_loss'])\n",
    "plt.plot(records['loss'])\n",
    "plt.yticks([0.00,0.40,0.60,0.80])\n",
    "plt.title('Loss value',fontsize=12)\n",
    "\n",
    "ax          = plt.gca()\n",
    "ax.set_xticklabels([])\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(records['val_acc'])\n",
    "plt.plot(records['acc'])\n",
    "plt.yticks([0.6,0.7,0.8,0.9])\n",
    "plt.title('Accuracy',fontsize=12)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "v2.1 Image Classifier",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
