{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2423 images belonging to 3 classes.\n",
      "Found 724 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.layers import AveragePooling2D, add\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "TRAIN_DIR = r\"D:\\NUS_TERM2_CA2\\Train\"\n",
    "TEST_DIR = r\"D:\\NUS_TERM2_CA2\\Validation\"\n",
    "# TRAIN_DIR = r\"C:\\Users\\guofe\\Downloads\\CA2_Data\"\n",
    "\n",
    "HEIGHT = 300\n",
    "WIDTH = 300\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    rotation_range=90,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    rescale=1./255)\n",
    "\n",
    "datagen2 = ImageDataGenerator(\n",
    "    rescale=1./255)\n",
    "\n",
    "\n",
    "train_generator = datagen.flow_from_directory(TRAIN_DIR,\n",
    "                                                    target_size=(HEIGHT, WIDTH),\n",
    "                                                    batch_size=BATCH_SIZE)\n",
    "\n",
    "validation_generator = datagen2.flow_from_directory(TEST_DIR,\n",
    "                                                    target_size=(HEIGHT, WIDTH),\n",
    "                                                    batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "class_list = [\"food\", \"landmark\", \"people\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 300, 300, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Inpt_conv (Conv2D)              (None, 300, 300, 16) 448         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Inpt_bn (BatchNormalization)    (None, 300, 300, 16) 64          Inpt_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Inpt_relu (Activation)          (None, 300, 300, 16) 0           Inpt_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_Res1_conv (Conv2D)    (None, 300, 300, 16) 2320        Inpt_relu[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_Res1_bn (BatchNormali (None, 300, 300, 16) 64          Stg1_Blk1_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_Res1_relu (Activation (None, 300, 300, 16) 0           Stg1_Blk1_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_Res2_conv (Conv2D)    (None, 300, 300, 16) 2320        Stg1_Blk1_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_Res2_bn (BatchNormali (None, 300, 300, 16) 64          Stg1_Blk1_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_add (Add)             (None, 300, 300, 16) 0           Inpt_relu[0][0]                  \n",
      "                                                                 Stg1_Blk1_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_relu (Activation)     (None, 300, 300, 16) 0           Stg1_Blk1_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_Res1_conv (Conv2D)    (None, 300, 300, 16) 2320        Stg1_Blk1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_Res1_bn (BatchNormali (None, 300, 300, 16) 64          Stg1_Blk2_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_Res1_relu (Activation (None, 300, 300, 16) 0           Stg1_Blk2_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_Res2_conv (Conv2D)    (None, 300, 300, 16) 2320        Stg1_Blk2_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_Res2_bn (BatchNormali (None, 300, 300, 16) 64          Stg1_Blk2_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_add (Add)             (None, 300, 300, 16) 0           Stg1_Blk1_relu[0][0]             \n",
      "                                                                 Stg1_Blk2_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_relu (Activation)     (None, 300, 300, 16) 0           Stg1_Blk2_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_Res1_conv (Conv2D)    (None, 300, 300, 16) 2320        Stg1_Blk2_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_Res1_bn (BatchNormali (None, 300, 300, 16) 64          Stg1_Blk3_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_Res1_relu (Activation (None, 300, 300, 16) 0           Stg1_Blk3_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_Res2_conv (Conv2D)    (None, 300, 300, 16) 2320        Stg1_Blk3_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_Res2_bn (BatchNormali (None, 300, 300, 16) 64          Stg1_Blk3_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_add (Add)             (None, 300, 300, 16) 0           Stg1_Blk2_relu[0][0]             \n",
      "                                                                 Stg1_Blk3_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_relu (Activation)     (None, 300, 300, 16) 0           Stg1_Blk3_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 300, 300, 16) 0           Stg1_Blk3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_Res1_conv (Conv2D)    (None, 150, 150, 32) 4640        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_Res1_bn (BatchNormali (None, 150, 150, 32) 128         Stg2_Blk1_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_Res1_relu (Activation (None, 150, 150, 32) 0           Stg2_Blk1_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_Res2_conv (Conv2D)    (None, 150, 150, 32) 9248        Stg2_Blk1_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_lin_conv (Conv2D)     (None, 150, 150, 32) 544         dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_Res2_bn (BatchNormali (None, 150, 150, 32) 128         Stg2_Blk1_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_add (Add)             (None, 150, 150, 32) 0           Stg2_Blk1_lin_conv[0][0]         \n",
      "                                                                 Stg2_Blk1_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_relu (Activation)     (None, 150, 150, 32) 0           Stg2_Blk1_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_Res1_conv (Conv2D)    (None, 150, 150, 32) 9248        Stg2_Blk1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_Res1_bn (BatchNormali (None, 150, 150, 32) 128         Stg2_Blk2_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_Res1_relu (Activation (None, 150, 150, 32) 0           Stg2_Blk2_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_Res2_conv (Conv2D)    (None, 150, 150, 32) 9248        Stg2_Blk2_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_Res2_bn (BatchNormali (None, 150, 150, 32) 128         Stg2_Blk2_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_add (Add)             (None, 150, 150, 32) 0           Stg2_Blk1_relu[0][0]             \n",
      "                                                                 Stg2_Blk2_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_relu (Activation)     (None, 150, 150, 32) 0           Stg2_Blk2_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_Res1_conv (Conv2D)    (None, 150, 150, 32) 9248        Stg2_Blk2_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_Res1_bn (BatchNormali (None, 150, 150, 32) 128         Stg2_Blk3_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_Res1_relu (Activation (None, 150, 150, 32) 0           Stg2_Blk3_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_Res2_conv (Conv2D)    (None, 150, 150, 32) 9248        Stg2_Blk3_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_Res2_bn (BatchNormali (None, 150, 150, 32) 128         Stg2_Blk3_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_add (Add)             (None, 150, 150, 32) 0           Stg2_Blk2_relu[0][0]             \n",
      "                                                                 Stg2_Blk3_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_relu (Activation)     (None, 150, 150, 32) 0           Stg2_Blk3_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 150, 150, 32) 0           Stg2_Blk3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_Res1_conv (Conv2D)    (None, 75, 75, 64)   18496       dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_Res1_bn (BatchNormali (None, 75, 75, 64)   256         Stg3_Blk1_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_Res1_relu (Activation (None, 75, 75, 64)   0           Stg3_Blk1_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_Res2_conv (Conv2D)    (None, 75, 75, 64)   36928       Stg3_Blk1_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_lin_conv (Conv2D)     (None, 75, 75, 64)   2112        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_Res2_bn (BatchNormali (None, 75, 75, 64)   256         Stg3_Blk1_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_add (Add)             (None, 75, 75, 64)   0           Stg3_Blk1_lin_conv[0][0]         \n",
      "                                                                 Stg3_Blk1_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_relu (Activation)     (None, 75, 75, 64)   0           Stg3_Blk1_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_Res1_conv (Conv2D)    (None, 75, 75, 64)   36928       Stg3_Blk1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_Res1_bn (BatchNormali (None, 75, 75, 64)   256         Stg3_Blk2_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_Res1_relu (Activation (None, 75, 75, 64)   0           Stg3_Blk2_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_Res2_conv (Conv2D)    (None, 75, 75, 64)   36928       Stg3_Blk2_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_Res2_bn (BatchNormali (None, 75, 75, 64)   256         Stg3_Blk2_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_add (Add)             (None, 75, 75, 64)   0           Stg3_Blk1_relu[0][0]             \n",
      "                                                                 Stg3_Blk2_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_relu (Activation)     (None, 75, 75, 64)   0           Stg3_Blk2_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_Res1_conv (Conv2D)    (None, 75, 75, 64)   36928       Stg3_Blk2_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_Res1_bn (BatchNormali (None, 75, 75, 64)   256         Stg3_Blk3_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_Res1_relu (Activation (None, 75, 75, 64)   0           Stg3_Blk3_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_Res2_conv (Conv2D)    (None, 75, 75, 64)   36928       Stg3_Blk3_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_Res2_bn (BatchNormali (None, 75, 75, 64)   256         Stg3_Blk3_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_add (Add)             (None, 75, 75, 64)   0           Stg3_Blk2_relu[0][0]             \n",
      "                                                                 Stg3_Blk3_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_relu (Activation)     (None, 75, 75, 64)   0           Stg3_Blk3_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 75, 75, 64)   0           Stg3_Blk3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg4_Blk1_Res1_conv (Conv2D)    (None, 38, 38, 128)  73856       dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Stg4_Blk1_Res1_bn (BatchNormali (None, 38, 38, 128)  512         Stg4_Blk1_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg4_Blk1_Res1_relu (Activation (None, 38, 38, 128)  0           Stg4_Blk1_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg4_Blk1_Res2_conv (Conv2D)    (None, 38, 38, 128)  147584      Stg4_Blk1_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg4_Blk1_lin_conv (Conv2D)     (None, 38, 38, 128)  8320        dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Stg4_Blk1_Res2_bn (BatchNormali (None, 38, 38, 128)  512         Stg4_Blk1_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg4_Blk1_add (Add)             (None, 38, 38, 128)  0           Stg4_Blk1_lin_conv[0][0]         \n",
      "                                                                 Stg4_Blk1_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg4_Blk1_relu (Activation)     (None, 38, 38, 128)  0           Stg4_Blk1_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg4_Blk2_Res1_conv (Conv2D)    (None, 38, 38, 128)  147584      Stg4_Blk1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg4_Blk2_Res1_bn (BatchNormali (None, 38, 38, 128)  512         Stg4_Blk2_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg4_Blk2_Res1_relu (Activation (None, 38, 38, 128)  0           Stg4_Blk2_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg4_Blk2_Res2_conv (Conv2D)    (None, 38, 38, 128)  147584      Stg4_Blk2_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg4_Blk2_Res2_bn (BatchNormali (None, 38, 38, 128)  512         Stg4_Blk2_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg4_Blk2_add (Add)             (None, 38, 38, 128)  0           Stg4_Blk1_relu[0][0]             \n",
      "                                                                 Stg4_Blk2_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg4_Blk2_relu (Activation)     (None, 38, 38, 128)  0           Stg4_Blk2_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg4_Blk3_Res1_conv (Conv2D)    (None, 38, 38, 128)  147584      Stg4_Blk2_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg4_Blk3_Res1_bn (BatchNormali (None, 38, 38, 128)  512         Stg4_Blk3_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg4_Blk3_Res1_relu (Activation (None, 38, 38, 128)  0           Stg4_Blk3_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg4_Blk3_Res2_conv (Conv2D)    (None, 38, 38, 128)  147584      Stg4_Blk3_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg4_Blk3_Res2_bn (BatchNormali (None, 38, 38, 128)  512         Stg4_Blk3_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg4_Blk3_add (Add)             (None, 38, 38, 128)  0           Stg4_Blk2_relu[0][0]             \n",
      "                                                                 Stg4_Blk3_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg4_Blk3_relu (Activation)     (None, 38, 38, 128)  0           Stg4_Blk3_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 38, 38, 128)  0           Stg4_Blk3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "AvgPool (AveragePooling2D)      (None, 4, 4, 128)    0           dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 2048)         0           AvgPool[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 3)            6147        flatten_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,103,107\n",
      "Trainable params: 1,100,195\n",
      "Non-trainable params: 2,912\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "seed = 29\n",
    "np.random.seed(seed)\n",
    "\n",
    "optmz = optimizers.Adam(lr=0.001)\n",
    "\n",
    "def resLyr(inputs,\n",
    "           numFilters=16,\n",
    "           kernelSz=3,\n",
    "           strides=1,\n",
    "           activation='relu',\n",
    "           batchNorm=True,\n",
    "           convFirst=True,\n",
    "           lyrName=None):\n",
    "  \n",
    "    convLyr = Conv2D(numFilters,\n",
    "                     kernel_size=kernelSz,\n",
    "                     strides=strides,\n",
    "                     padding='same',\n",
    "                     kernel_initializer='he_normal',\n",
    "                     kernel_regularizer=l2(1e-4),\n",
    "                     name=lyrName + '_conv' if lyrName else None)\n",
    "    x = inputs\n",
    "    if convFirst:\n",
    "        x = convLyr(x)\n",
    "        if batchNorm:\n",
    "            x = BatchNormalization(name=lyrName + '_bn' if lyrName else None)(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation, name=lyrName + '_' + activation if lyrName else None)(x)\n",
    "    else:\n",
    "        if batchNorm:\n",
    "            x = BatchNormalization(name=lyrName + '_bn' if lyrName else None)(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation, name=lyrName + '_' + activation if lyrName else None)(x)\n",
    "        x = convLyr(x)\n",
    "  \n",
    "    return x\n",
    "\n",
    "\n",
    "def resBlkV1(inputs,\n",
    "             numFilters=16,\n",
    "             numBlocks=3,\n",
    "             downsampleOnFirst=True,\n",
    "             names=None):\n",
    "  \n",
    "    x = inputs\n",
    "    for run in range(0, numBlocks):\n",
    "        strides = 1\n",
    "        blkStr = str(run + 1)\n",
    "        \n",
    "        if downsampleOnFirst and run == 0:\n",
    "            strides = 2\n",
    "            \n",
    "        y = resLyr(inputs=x, numFilters=numFilters, strides=strides, lyrName=names+'_Blk'+blkStr+'_Res1' if names else None)\n",
    "        y = resLyr(inputs=y, numFilters=numFilters, activation=None, lyrName=names+'_Blk'+blkStr+'_Res2' if names else None) \n",
    "        \n",
    "        if downsampleOnFirst and run == 0:\n",
    "            x = resLyr(inputs=x, numFilters=numFilters, kernelSz=1, \n",
    "                       strides=strides, activation=None, batchNorm=False, \n",
    "                       lyrName=names+'_Blk'+blkStr+'_lin' if names else None)\n",
    "\n",
    "        x = add([x, y], name=names+'_Blk'+blkStr+'_add' if names else None) \n",
    "\n",
    "        x = Activation('relu',  name=names+'_Blk'+blkStr+'_relu' if names else None)(x)   \n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def createResNetV1(inputShape=(32, 32, 3),\n",
    "                   numClasses=3):\n",
    "  \n",
    "    inputs = Input(shape=inputShape)\n",
    "    v = resLyr(inputs,\n",
    "               lyrName='Inpt')\n",
    "    v = resBlkV1(inputs=v,\n",
    "                 numFilters=16,\n",
    "                 numBlocks=3,\n",
    "                 downsampleOnFirst=False,\n",
    "                 names='Stg1')\n",
    "    v = Dropout(0.3)(v)\n",
    "    \n",
    "    v = resBlkV1(inputs=v,\n",
    "                 numFilters=32,\n",
    "                 numBlocks=3,\n",
    "                 downsampleOnFirst=True,\n",
    "                 names='Stg2')\n",
    "    v = Dropout(0.3)(v)\n",
    "    \n",
    "    v = resBlkV1(inputs=v,\n",
    "                 numFilters=64,\n",
    "                 numBlocks=3,\n",
    "                 downsampleOnFirst=True,\n",
    "                 names='Stg3')\n",
    "    v = Dropout(0.3)(v)\n",
    "    \n",
    "    v = resBlkV1(inputs=v,\n",
    "                 numFilters=128,\n",
    "                 numBlocks=3,\n",
    "                 downsampleOnFirst=True,\n",
    "                 names='Stg4')    \n",
    "    v = Dropout(0.3)(v)\n",
    "    \n",
    "    v = AveragePooling2D(pool_size=8,\n",
    "                         name='AvgPool')(v)\n",
    "    v = Flatten()(v)\n",
    "    outputs = Dense(numClasses,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(v)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optmz,\n",
    "                  metrics=['accuracy'])\n",
    "  \n",
    "    return model\n",
    "\n",
    "model = createResNetV1(inputShape=(HEIGHT, WIDTH, 3))  # This is meant for training\n",
    "modelGo = createResNetV1(inputShape=(HEIGHT, WIDTH, 3))  # This is used for final testing\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.01\n",
      "Epoch 1/100\n",
      "67/67 [==============================] - 46s 684ms/step - loss: 4.8465 - acc: 0.3682 - val_loss: 657264.3729 - val_acc: 0.3011\n",
      "Learning rate:  0.01\n",
      "Epoch 2/100\n",
      "67/67 [==============================] - 24s 354ms/step - loss: 2.0117 - acc: 0.3899 - val_loss: 18.4534 - val_acc: 0.3011\n",
      "Learning rate:  0.01\n",
      "Epoch 3/100\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 1.7248 - acc: 0.4459 - val_loss: 2.2194 - val_acc: 0.4461\n",
      "Learning rate:  0.01\n",
      "Epoch 4/100\n",
      "67/67 [==============================] - 25s 366ms/step - loss: 1.5724 - acc: 0.4049 - val_loss: 1.4949 - val_acc: 0.5387\n",
      "Learning rate:  0.01\n",
      "Epoch 5/100\n",
      "67/67 [==============================] - 26s 386ms/step - loss: 1.4600 - acc: 0.4459 - val_loss: 1.5841 - val_acc: 0.5663\n",
      "Learning rate:  0.01\n",
      "Epoch 6/100\n",
      "67/67 [==============================] - 25s 370ms/step - loss: 1.4542 - acc: 0.5149 - val_loss: 1.8373 - val_acc: 0.6271\n",
      "Learning rate:  0.01\n",
      "Epoch 7/100\n",
      "67/67 [==============================] - 25s 369ms/step - loss: 1.2938 - acc: 0.5402 - val_loss: 1.2974 - val_acc: 0.5608\n",
      "Learning rate:  0.01\n",
      "Epoch 8/100\n",
      "67/67 [==============================] - 25s 378ms/step - loss: 1.2283 - acc: 0.5224 - val_loss: 1.2245 - val_acc: 0.5428\n",
      "Learning rate:  0.01\n",
      "Epoch 9/100\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 1.1848 - acc: 0.5597 - val_loss: 1.5992 - val_acc: 0.6160\n",
      "Learning rate:  0.01\n",
      "Epoch 10/100\n",
      "67/67 [==============================] - 26s 382ms/step - loss: 1.2726 - acc: 0.5466 - val_loss: 1.5140 - val_acc: 0.4586\n",
      "Learning rate:  0.01\n",
      "Epoch 11/100\n",
      "67/67 [==============================] - 26s 381ms/step - loss: 1.2186 - acc: 0.5570 - val_loss: 1.0732 - val_acc: 0.6298\n",
      "Learning rate:  0.001\n",
      "Epoch 12/100\n",
      "67/67 [==============================] - 25s 379ms/step - loss: 1.0863 - acc: 0.6511 - val_loss: 0.9998 - val_acc: 0.6644\n",
      "Learning rate:  0.001\n",
      "Epoch 13/100\n",
      "67/67 [==============================] - 26s 381ms/step - loss: 1.0170 - acc: 0.6698 - val_loss: 0.9545 - val_acc: 0.6948\n",
      "Learning rate:  0.001\n",
      "Epoch 14/100\n",
      "67/67 [==============================] - 26s 384ms/step - loss: 0.9705 - acc: 0.6716 - val_loss: 0.9356 - val_acc: 0.7169\n",
      "Learning rate:  0.001\n",
      "Epoch 15/100\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.9669 - acc: 0.6916 - val_loss: 0.9902 - val_acc: 0.6464\n",
      "Learning rate:  0.001\n",
      "Epoch 16/100\n",
      "67/67 [==============================] - 25s 371ms/step - loss: 0.9208 - acc: 0.7071 - val_loss: 0.9066 - val_acc: 0.6961\n",
      "Learning rate:  0.001\n",
      "Epoch 17/100\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.9305 - acc: 0.7034 - val_loss: 1.0058 - val_acc: 0.6588\n",
      "Learning rate:  0.001\n",
      "Epoch 18/100\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 0.8197 - acc: 0.7668 - val_loss: 0.9670 - val_acc: 0.6989\n",
      "Learning rate:  0.001\n",
      "Epoch 19/100\n",
      "67/67 [==============================] - 26s 382ms/step - loss: 0.8885 - acc: 0.7351 - val_loss: 0.8851 - val_acc: 0.7044\n",
      "Learning rate:  0.001\n",
      "Epoch 20/100\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.9188 - acc: 0.7103 - val_loss: 0.9232 - val_acc: 0.7017\n",
      "Learning rate:  0.001\n",
      "Epoch 21/100\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.8145 - acc: 0.7500 - val_loss: 1.1189 - val_acc: 0.6506\n",
      "Learning rate:  0.001\n",
      "Epoch 22/100\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 0.7928 - acc: 0.7780 - val_loss: 0.8248 - val_acc: 0.7362\n",
      "Learning rate:  0.001\n",
      "Epoch 23/100\n",
      "67/67 [==============================] - 25s 378ms/step - loss: 0.8392 - acc: 0.7593 - val_loss: 0.8746 - val_acc: 0.7058\n",
      "Learning rate:  0.001\n",
      "Epoch 24/100\n",
      "67/67 [==============================] - 25s 380ms/step - loss: 0.8098 - acc: 0.7593 - val_loss: 0.6848 - val_acc: 0.7997\n",
      "Learning rate:  0.001\n",
      "Epoch 25/100\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.8129 - acc: 0.7537 - val_loss: 0.8245 - val_acc: 0.7348\n",
      "Learning rate:  0.001\n",
      "Epoch 26/100\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.7629 - acc: 0.7817 - val_loss: 0.7772 - val_acc: 0.7583\n",
      "Learning rate:  0.001\n",
      "Epoch 27/100\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.7860 - acc: 0.7720 - val_loss: 0.7136 - val_acc: 0.7859\n",
      "Learning rate:  0.001\n",
      "Epoch 28/100\n",
      "67/67 [==============================] - 26s 382ms/step - loss: 0.7940 - acc: 0.7705 - val_loss: 0.6739 - val_acc: 0.8025\n",
      "Learning rate:  0.001\n",
      "Epoch 29/100\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.7199 - acc: 0.7705 - val_loss: 0.8148 - val_acc: 0.7403\n",
      "Learning rate:  0.001\n",
      "Epoch 30/100\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 0.7761 - acc: 0.7477 - val_loss: 0.6660 - val_acc: 0.8039\n",
      "Learning rate:  0.001\n",
      "Epoch 31/100\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 0.7945 - acc: 0.7556 - val_loss: 0.8993 - val_acc: 0.6920\n",
      "Learning rate:  0.001\n",
      "Epoch 32/100\n",
      "67/67 [==============================] - 26s 383ms/step - loss: 0.7871 - acc: 0.7537 - val_loss: 0.7312 - val_acc: 0.7514\n",
      "Learning rate:  0.001\n",
      "Epoch 33/100\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.8211 - acc: 0.7421 - val_loss: 0.8248 - val_acc: 0.7265\n",
      "Learning rate:  0.001\n",
      "Epoch 34/100\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 0.7869 - acc: 0.7575 - val_loss: 0.7280 - val_acc: 0.7610\n",
      "Learning rate:  0.001\n",
      "Epoch 35/100\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.7564 - acc: 0.7705 - val_loss: 0.7593 - val_acc: 0.7472\n",
      "Learning rate:  0.001\n",
      "Epoch 36/100\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.7372 - acc: 0.7799 - val_loss: 0.8138 - val_acc: 0.7113\n",
      "Learning rate:  0.001\n",
      "Epoch 37/100\n",
      "67/67 [==============================] - 26s 383ms/step - loss: 0.7749 - acc: 0.7626 - val_loss: 0.8394 - val_acc: 0.7293\n",
      "Learning rate:  0.001\n",
      "Epoch 38/100\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.7311 - acc: 0.7761 - val_loss: 0.6677 - val_acc: 0.7983\n",
      "Learning rate:  0.001\n",
      "Epoch 39/100\n",
      "67/67 [==============================] - 24s 354ms/step - loss: 0.7498 - acc: 0.7668 - val_loss: 0.8317 - val_acc: 0.7127\n",
      "Learning rate:  0.001\n",
      "Epoch 40/100\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.7207 - acc: 0.7743 - val_loss: 0.7840 - val_acc: 0.6989\n",
      "Learning rate:  0.001\n",
      "Epoch 41/100\n",
      "67/67 [==============================] - 25s 380ms/step - loss: 0.7371 - acc: 0.7705 - val_loss: 0.8361 - val_acc: 0.7362\n",
      "Learning rate:  0.001\n",
      "Epoch 42/100\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.7394 - acc: 0.7589 - val_loss: 0.6925 - val_acc: 0.7997\n",
      "Learning rate:  0.001\n",
      "Epoch 43/100\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.7376 - acc: 0.7631 - val_loss: 0.5883 - val_acc: 0.8370\n",
      "Learning rate:  0.001\n",
      "Epoch 44/100\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.6774 - acc: 0.7780 - val_loss: 0.8441 - val_acc: 0.7113\n",
      "Learning rate:  0.001\n",
      "Epoch 45/100\n",
      "67/67 [==============================] - 25s 366ms/step - loss: 0.7425 - acc: 0.7463 - val_loss: 0.7272 - val_acc: 0.7776\n",
      "Learning rate:  0.001\n",
      "Epoch 46/100\n",
      "67/67 [==============================] - 26s 383ms/step - loss: 0.6754 - acc: 0.7873 - val_loss: 0.8627 - val_acc: 0.7044\n",
      "Learning rate:  0.001\n",
      "Epoch 47/100\n",
      "67/67 [==============================] - 25s 369ms/step - loss: 0.7275 - acc: 0.7556 - val_loss: 0.6700 - val_acc: 0.7749\n",
      "Learning rate:  0.001\n",
      "Epoch 48/100\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.7018 - acc: 0.7743 - val_loss: 0.7802 - val_acc: 0.7099\n",
      "Learning rate:  0.001\n",
      "Epoch 49/100\n",
      "67/67 [==============================] - 25s 369ms/step - loss: 0.7221 - acc: 0.7743 - val_loss: 0.7436 - val_acc: 0.7486\n",
      "Learning rate:  0.001\n",
      "Epoch 50/100\n",
      "67/67 [==============================] - 25s 381ms/step - loss: 0.6436 - acc: 0.8187 - val_loss: 0.6622 - val_acc: 0.7873\n",
      "Learning rate:  0.001\n",
      "Epoch 51/100\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 0.6902 - acc: 0.7929 - val_loss: 0.9638 - val_acc: 0.7058\n",
      "Learning rate:  0.001\n",
      "Epoch 52/100\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.6710 - acc: 0.7701 - val_loss: 0.6813 - val_acc: 0.7583\n",
      "Learning rate:  0.001\n",
      "Epoch 53/100\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.7381 - acc: 0.7519 - val_loss: 0.8048 - val_acc: 0.6809\n",
      "Learning rate:  0.001\n",
      "Epoch 54/100\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.7083 - acc: 0.7724 - val_loss: 1.0582 - val_acc: 0.5677\n",
      "Learning rate:  0.001\n",
      "Epoch 55/100\n",
      "67/67 [==============================] - 25s 378ms/step - loss: 0.6526 - acc: 0.7724 - val_loss: 1.0529 - val_acc: 0.5884\n",
      "Learning rate:  0.001\n",
      "Epoch 56/100\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 0.6898 - acc: 0.7649 - val_loss: 0.6703 - val_acc: 0.7762\n",
      "Learning rate:  0.001\n",
      "Epoch 57/100\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.6220 - acc: 0.8190 - val_loss: 0.6911 - val_acc: 0.7569\n",
      "Learning rate:  0.001\n",
      "Epoch 58/100\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 0.6590 - acc: 0.7836 - val_loss: 1.1456 - val_acc: 0.6050\n",
      "Learning rate:  0.001\n",
      "Epoch 59/100\n",
      "67/67 [==============================] - 26s 385ms/step - loss: 0.6987 - acc: 0.7776 - val_loss: 1.1788 - val_acc: 0.4641\n",
      "Learning rate:  0.001\n",
      "Epoch 60/100\n",
      "67/67 [==============================] - 25s 369ms/step - loss: 0.6638 - acc: 0.7836 - val_loss: 0.5893 - val_acc: 0.8163\n",
      "Learning rate:  0.001\n",
      "Epoch 61/100\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.6613 - acc: 0.7966 - val_loss: 0.6181 - val_acc: 0.8066\n",
      "Learning rate:  0.001\n",
      "Epoch 62/100\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.5885 - acc: 0.8037 - val_loss: 1.0222 - val_acc: 0.7072\n",
      "Learning rate:  0.001\n",
      "Epoch 63/100\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 0.7052 - acc: 0.7705 - val_loss: 0.7900 - val_acc: 0.7334\n",
      "Learning rate:  0.001\n",
      "Epoch 64/100\n",
      "67/67 [==============================] - 26s 382ms/step - loss: 0.6403 - acc: 0.7817 - val_loss: 0.7263 - val_acc: 0.7624\n",
      "Learning rate:  0.001\n",
      "Epoch 65/100\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.6788 - acc: 0.7794 - val_loss: 0.5144 - val_acc: 0.8439\n",
      "Learning rate:  0.001\n",
      "Epoch 66/100\n",
      "67/67 [==============================] - 25s 375ms/step - loss: 0.6020 - acc: 0.8041 - val_loss: 0.5225 - val_acc: 0.8384\n",
      "Learning rate:  0.001\n",
      "Epoch 67/100\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.6298 - acc: 0.8097 - val_loss: 0.7873 - val_acc: 0.7169\n",
      "Learning rate:  0.001\n",
      "Epoch 68/100\n",
      "67/67 [==============================] - 25s 376ms/step - loss: 0.5222 - acc: 0.8545 - val_loss: 1.9481 - val_acc: 0.4599\n",
      "Learning rate:  0.001\n",
      "Epoch 69/100\n",
      "67/67 [==============================] - 24s 355ms/step - loss: 0.6364 - acc: 0.8097 - val_loss: 0.7567 - val_acc: 0.7790\n",
      "Learning rate:  0.001\n",
      "Epoch 70/100\n",
      "67/67 [==============================] - 25s 374ms/step - loss: 0.5655 - acc: 0.8396 - val_loss: 0.5008 - val_acc: 0.8522\n",
      "Learning rate:  0.001\n",
      "Epoch 71/100\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.7220 - acc: 0.7668 - val_loss: 1.4381 - val_acc: 0.3729\n",
      "Learning rate:  0.001\n",
      "Epoch 72/100\n",
      "67/67 [==============================] - 25s 372ms/step - loss: 0.5811 - acc: 0.8246 - val_loss: 0.5551 - val_acc: 0.8177\n",
      "Learning rate:  0.001\n",
      "Epoch 73/100\n",
      "67/67 [==============================] - 25s 376ms/step - loss: 0.6175 - acc: 0.8000 - val_loss: 0.7614 - val_acc: 0.7804\n",
      "Learning rate:  0.001\n",
      "Epoch 74/100\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.6314 - acc: 0.8004 - val_loss: 1.0545 - val_acc: 0.5732\n",
      "Learning rate:  0.001\n",
      "Epoch 75/100\n",
      "67/67 [==============================] - 25s 373ms/step - loss: 0.5622 - acc: 0.8116 - val_loss: 0.8271 - val_acc: 0.6837\n",
      "Learning rate:  0.001\n",
      "Epoch 76/100\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.6202 - acc: 0.7873 - val_loss: 1.0449 - val_acc: 0.5649\n",
      "Learning rate:  0.001\n",
      "Epoch 77/100\n",
      "67/67 [==============================] - 25s 372ms/step - loss: 0.5596 - acc: 0.8280 - val_loss: 0.7492 - val_acc: 0.7583\n",
      "Learning rate:  0.001\n",
      "Epoch 78/100\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 0.5676 - acc: 0.8172 - val_loss: 1.2725 - val_acc: 0.5166\n",
      "Learning rate:  0.001\n",
      "Epoch 79/100\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.5807 - acc: 0.8262 - val_loss: 1.2680 - val_acc: 0.6091\n",
      "Learning rate:  0.001\n",
      "Epoch 80/100\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 0.5626 - acc: 0.8284 - val_loss: 1.6113 - val_acc: 0.4572\n",
      "Learning rate:  0.001\n",
      "Epoch 81/100\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 0.5861 - acc: 0.7873 - val_loss: 0.4918 - val_acc: 0.8550\n",
      "Learning rate:  0.0001\n",
      "Epoch 82/100\n",
      "67/67 [==============================] - 26s 391ms/step - loss: 0.5149 - acc: 0.8299 - val_loss: 0.4745 - val_acc: 0.8564\n",
      "Learning rate:  0.0001\n",
      "Epoch 83/100\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.5576 - acc: 0.8228 - val_loss: 0.5734 - val_acc: 0.8108\n",
      "Learning rate:  0.0001\n",
      "Epoch 84/100\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.5323 - acc: 0.8414 - val_loss: 0.6485 - val_acc: 0.7638\n",
      "Learning rate:  0.0001\n",
      "Epoch 85/100\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 0.5094 - acc: 0.8545 - val_loss: 0.6178 - val_acc: 0.7790\n",
      "Learning rate:  0.0001\n",
      "Epoch 86/100\n",
      "67/67 [==============================] - 26s 389ms/step - loss: 0.4934 - acc: 0.8470 - val_loss: 0.6600 - val_acc: 0.7666\n",
      "Learning rate:  0.0001\n",
      "Epoch 87/100\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.5124 - acc: 0.8321 - val_loss: 0.7899 - val_acc: 0.7113\n",
      "Learning rate:  0.0001\n",
      "Epoch 88/100\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.5485 - acc: 0.8187 - val_loss: 0.6693 - val_acc: 0.7638\n",
      "Learning rate:  0.0001\n",
      "Epoch 89/100\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.4616 - acc: 0.8657 - val_loss: 0.5422 - val_acc: 0.8204\n",
      "Learning rate:  0.0001\n",
      "Epoch 90/100\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 0.4929 - acc: 0.8414 - val_loss: 0.5672 - val_acc: 0.8163\n",
      "Learning rate:  0.0001\n",
      "Epoch 91/100\n",
      "67/67 [==============================] - 26s 385ms/step - loss: 0.5099 - acc: 0.8396 - val_loss: 0.5319 - val_acc: 0.8232\n",
      "Learning rate:  0.0001\n",
      "Epoch 92/100\n",
      "67/67 [==============================] - 25s 378ms/step - loss: 0.5015 - acc: 0.8526 - val_loss: 0.5875 - val_acc: 0.8025\n",
      "Learning rate:  0.0001\n",
      "Epoch 93/100\n",
      "67/67 [==============================] - 24s 355ms/step - loss: 0.4904 - acc: 0.8433 - val_loss: 0.6078 - val_acc: 0.7928\n",
      "Learning rate:  0.0001\n",
      "Epoch 94/100\n",
      "67/67 [==============================] - 26s 381ms/step - loss: 0.4822 - acc: 0.8523 - val_loss: 0.5203 - val_acc: 0.8329\n",
      "Learning rate:  0.0001\n",
      "Epoch 95/100\n",
      "67/67 [==============================] - 25s 376ms/step - loss: 0.4861 - acc: 0.8470 - val_loss: 0.7809 - val_acc: 0.7099\n",
      "Learning rate:  0.0001\n",
      "Epoch 96/100\n",
      "67/67 [==============================] - 25s 372ms/step - loss: 0.4157 - acc: 0.8787 - val_loss: 0.8540 - val_acc: 0.6768\n",
      "Learning rate:  0.0001\n",
      "Epoch 97/100\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 0.4820 - acc: 0.8470 - val_loss: 0.6541 - val_acc: 0.7693\n",
      "Learning rate:  0.0001\n",
      "Epoch 98/100\n",
      "67/67 [==============================] - 25s 379ms/step - loss: 0.5375 - acc: 0.8187 - val_loss: 0.6662 - val_acc: 0.7721\n",
      "Learning rate:  0.0001\n",
      "Epoch 99/100\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 0.5167 - acc: 0.8377 - val_loss: 0.6760 - val_acc: 0.7541\n",
      "Learning rate:  0.0001\n",
      "Epoch 100/100\n",
      "67/67 [==============================] - 25s 375ms/step - loss: 0.5035 - acc: 0.8243 - val_loss: 0.6167 - val_acc: 0.7914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e87adf6518>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 128\n",
    "num_train_images = 2423\n",
    "\n",
    "def lrSchedule(epoch):\n",
    "    lr = 1e-2\n",
    "\n",
    "    if epoch > 160:\n",
    "        lr *= 0.5e-3\n",
    "\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-3\n",
    "\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-2\n",
    "\n",
    "    elif epoch > 10:\n",
    "        lr *= 1e-1\n",
    "\n",
    "    print('Learning rate: ', lr)\n",
    "\n",
    "    return lr\n",
    "\n",
    "\n",
    "LRScheduler = LearningRateScheduler(lrSchedule)\n",
    "\n",
    "modelname = 'createResNetV1'\n",
    "filepath = modelname + '.hdf5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath,\n",
    "                            monitor='val_acc',\n",
    "                            verbose=0,\n",
    "                            save_best_only=True,\n",
    "                            mode='max')\n",
    "csv_logger = CSVLogger(modelname + '.csv')\n",
    "\n",
    "callbacks_list = [checkpoint, csv_logger, LRScheduler]\n",
    "\n",
    "# STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "# STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n",
    "                    \n",
    "model.fit_generator(generator=train_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    workers=12, \n",
    "                    shuffle=True,\n",
    "#                     steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "#                     validation_steps=STEP_SIZE_VALID,\n",
    "                    steps_per_epoch=num_train_images // BATCH_SIZE, \n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
