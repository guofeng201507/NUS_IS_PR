{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "bwvSlEyz8Q3W",
    "outputId": "5a03ea90-2f6e-4619-cc51-e1bccd946524",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create dataset...\n",
      "Finalizing all the data ....\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Nov  7 10:00:55 2017\n",
    "\n",
    "@author: NPBME\n",
    "\"\"\"\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Set up 'ggplot' style\n",
    "plt.style.use('ggplot')  # if want to use the default style, set 'classic'\n",
    "plt.rcParams['ytick.right'] = True\n",
    "plt.rcParams['ytick.labelright'] = True\n",
    "plt.rcParams['ytick.left'] = False\n",
    "plt.rcParams['ytick.labelleft'] = False\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "\n",
    "# Retrieve data  --------------------------------------------------------------\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "f = h5py.File('cad5sec.mat')\n",
    "X = f[\"data\"]\n",
    "Y = f[\"classLabel\"]\n",
    "data = np.array(X)\n",
    "data = np.transpose(data)\n",
    "label = np.array(Y)\n",
    "label = np.transpose(label)\n",
    "\n",
    "nor = data[0:32000]\n",
    "cad = data[32000:38120]\n",
    "\n",
    "\n",
    "# stepzation function ---------------------------------------------------------\n",
    "#\n",
    "#\n",
    "# This function creates segmenets of a 1D signal\n",
    "# It works in batch\n",
    "#\n",
    "#\n",
    "# Dependency:       numpy\n",
    "\n",
    "def makeSteps(dat, length, dist):\n",
    "    width = dat.shape[1]\n",
    "    numOfSteps = int(np.floor((width - length) / dist) + 1)\n",
    "\n",
    "    # Initialize the output\n",
    "    segments = np.zeros([dat.shape[0], numOfSteps, length],\n",
    "                        dtype=dat.dtype)\n",
    "\n",
    "    for l in range(numOfSteps):\n",
    "        segments[:, l, :] = dat[:, (l * dist):(l * dist + length)]\n",
    "\n",
    "    return segments\n",
    "\n",
    "\n",
    "# Splitting data into training and testing set---------------------------------\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "\n",
    "print('Create dataset...')\n",
    "trNor = nor[0:28800].copy()\n",
    "tsNor = nor[28800:32000].copy()\n",
    "trCad = cad[0:5000].copy()\n",
    "tsCad = cad[5000:6120].copy()\n",
    "\n",
    "# Create segments from the signals --------------------------------------------\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "length = 24\n",
    "dist = 6\n",
    "\n",
    "print('Finalizing all the data ....')\n",
    "trNorS = makeSteps(trNor, length, dist)\n",
    "tsNorS = makeSteps(tsNor, length, dist)\n",
    "trCadS = makeSteps(trCad, length, dist)\n",
    "tsCadS = makeSteps(tsCad, length, dist)\n",
    "\n",
    "trDat = np.vstack([trNorS, trCadS])\n",
    "tsDat = np.vstack([tsNorS, tsCadS])\n",
    "\n",
    "trLbl = np.vstack([np.zeros([trNorS.shape[0], 1]),\n",
    "                   np.ones([trCadS.shape[0], 1])])\n",
    "tsLbl = np.vstack([np.zeros([tsNorS.shape[0], 1]),\n",
    "                   np.ones([tsCadS.shape[0], 1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887
    },
    "colab_type": "code",
    "id": "flhQ0AQC8jGl",
    "outputId": "5931ed93-fe80-4d66-fd18-f79eb2b6253d",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating lstm model...\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 211, 24)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 207, 32)           3872      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 207, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 203, 32)           5152      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 101, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 97, 48)            7728      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 97, 48)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 93, 48)            11568     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 46, 48)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 42, 64)            15424     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 42, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 38, 64)            20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 19, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 19, 8)             2336      \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 19, 4)             208       \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 2)                 56        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 66,891\n",
      "Trainable params: 66,891\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating model --------------------------------------------------------------\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "print('Creating lstm model...')\n",
    "\n",
    "modelname = 'wks3_2_2'\n",
    "\n",
    "\n",
    "def createModel():\n",
    "    inputs = Input(shape=(trDat.shape[1], length))\n",
    "    y = Conv1D(32, 5, activation='relu')(inputs)\n",
    "    y = Dropout(0.25)(y)\n",
    "    y = Conv1D(32, 5, activation='relu')(y)\n",
    "    y = MaxPooling1D(2)(y)\n",
    "    y = Conv1D(48, 5, activation='relu')(y)\n",
    "    y = Dropout(0.5)(y)\n",
    "    y = Conv1D(48, 5, activation='relu')(y)\n",
    "    y = MaxPooling1D(2)(y)\n",
    "    y = Conv1D(64, 5, activation='relu')(y)\n",
    "    y = Dropout(0.5)(y)\n",
    "    y = Conv1D(64, 5, activation='relu')(y)\n",
    "    y = MaxPooling1D(2)(y)\n",
    "    y = LSTM(8,\n",
    "             return_sequences=True,\n",
    "             dropout=0.5,\n",
    "             recurrent_dropout=0.5)(y)\n",
    "    y = LSTM(4,\n",
    "             return_sequences=True,\n",
    "             dropout=0.5,\n",
    "             recurrent_dropout=0.5)(y)\n",
    "    y = LSTM(2)(y)\n",
    "    y = Dense(1, activation='sigmoid')(y)\n",
    "    model = Model(inputs=inputs, outputs=y)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "    # Setup the models\n",
    "\n",
    "\n",
    "model = createModel()  # This is meant for training\n",
    "modelGo = createModel()  # This is used for final testing\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "dq6ScF9D_ich",
    "outputId": "c4346bfc-0d67-4ae6-a2f8-8e272f872189",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33800 samples, validate on 4320 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "2 root error(s) found.\n  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node conv1d/conv1d}}]]\n\t [[loss/mul/_285]]\n  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node conv1d/conv1d}}]]\n0 successful operations.\n0 derived errors ignored.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ea738e60dda1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m           callbacks=callbacks_list)\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# ......................................................................\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guofe\\workspace\\nus_is_pr\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\guofe\\workspace\\nus_is_pr\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guofe\\workspace\\nus_is_pr\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32mc:\\users\\guofe\\workspace\\nus_is_pr\\venv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: 2 root error(s) found.\n  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node conv1d/conv1d}}]]\n\t [[loss/mul/_285]]\n  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node conv1d/conv1d}}]]\n0 successful operations.\n0 derived errors ignored."
     ]
    }
   ],
   "source": [
    "# Create checkpoint for the training\n",
    "# This checkpoint performs model saving when\n",
    "# an epoch gives highest testing accuracy\n",
    "filepath = modelname + \".hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=0,\n",
    "                             save_best_only=True,\n",
    "                             mode='max')\n",
    "\n",
    "# Log the epoch detail into csv\n",
    "csv_logger = CSVLogger(modelname + '.csv')\n",
    "callbacks_list = [checkpoint, csv_logger]\n",
    "\n",
    "# .............................................................................\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "# This is where the training starts\n",
    "model.fit(trDat,\n",
    "          trLbl,\n",
    "          validation_data=(tsDat, tsLbl),\n",
    "          epochs=30,\n",
    "          batch_size=256,\n",
    "          shuffle=True,\n",
    "          callbacks=callbacks_list)\n",
    "\n",
    "# ......................................................................\n",
    "\n",
    "\n",
    "# Now the training is complete, we get\n",
    "# another object to load the weights\n",
    "# compile it, so that we can do\n",
    "# final evaluation on it\n",
    "modelGo.load_weights(filepath)\n",
    "modelGo.compile(loss='categorical_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# .......................................................................\n",
    "\n",
    "\n",
    "# Make classification on the test dataset\n",
    "predicts = modelGo.predict(tsDat)\n",
    "\n",
    "labelname = ['Normal', 'CAD']\n",
    "# the labels for the classfication report\n",
    "\n",
    "\n",
    "testScores = metrics.accuracy_score(tsLbl, predicts.round())\n",
    "confusion = metrics.confusion_matrix(tsLbl, predicts.round())\n",
    "\n",
    "print(\"Best accuracy (on testing dataset): %.2f%%\" % (testScores * 100))\n",
    "print(metrics.classification_report(tsLbl, predicts.round(), target_names=labelname, digits=4))\n",
    "print(confusion)\n",
    "\n",
    "# ..................................................................\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "records = pd.read_csv(modelname + '.csv')\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "plt.plot(records['val_loss'])\n",
    "plt.plot(records['loss'])\n",
    "plt.yticks([0.00, 0.40, 0.60, 0.80])\n",
    "plt.title('Loss value', fontsize=12)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_xticklabels([])\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(records['val_acc'])\n",
    "plt.plot(records['acc'])\n",
    "plt.yticks([0.6, 0.7, 0.8, 0.9])\n",
    "plt.title('Accuracy', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7rvcZugx8ZwV"
   },
   "outputs": [],
   "source": [
    "# ................................................................\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(model,\n",
    "           to_file=modelname + '_model.pdf',\n",
    "           #    to_file='model.png',\n",
    "           show_shapes=True,\n",
    "           show_layer_names=False,\n",
    "           rankdir='TB')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "wks3_2_2_Lu Jiahao.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
